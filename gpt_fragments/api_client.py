from os import environ
from pathlib import Path
import re

from dotenv import load_dotenv
from openai import OpenAI

dotenv_path = Path('enviroment/.env')
load_dotenv(dotenv_path)

OPENAI_TOKEN = environ.get('OPENAI_TOKEN')

class GPTClient:
    """
    A class representing a client for interacting with OpenAI's GPT models.

    Attributes:
        client (OpenAI): An instance of the OpenAI class to use for API requests.
    
    Methods:
        generate_summary_and_tags(content, prompt=None): Generates a summary and tags for the given content using the GPT-4o-mini model.
            Parameters:
                content (str): The content for which to generate a summary and tags.
                prompt (str): Optional prompt for the GPT model.
            Returns:
                tuple: A tuple containing the title, summary, and tags generated by the GPT model.
    """    
    def __init__(self):
        """
        Initialize the OpenAI client with the provided API key.

        Args:
            None

        Returns:
            None
        """        
        self.client = OpenAI(api_key=OPENAI_TOKEN)
        self.prompt_cache = {}

    def generate_summary_and_tags(self, content: str, prompt: str = None) -> tuple:
        """
        Generate a summary, title, and tags based on input content and prompt.

        Args:
            self: The class instance.
            content (str): The content for which to generate a summary, title, and tags.
            prompt (str, optional): The prompt to provide context for generating the response. Default is None.

        Returns:
            tuple: A tuple containing the title (str), summary (str), and tags (list) generated based on the input content.

        Raises:
            IndexError: If the response choices are empty or incomplete.
            re.error: If there is an issue with the regular expression matching.
        """        
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system",
                 "content": prompt},
                {"role": "user",
                 "content": f"Para el siguiente contenido, quiero que generes una respuesta en este formato específico:\n\n**Título:** [Título del artículo]\n\n**Resumen:** [Resumen del contenido]\n\n**Tags:** [#Tag1 #Tag2 ...]\n\nContenido:\n{content}"},
            ],
            max_tokens=1000,
        )
        response = response.choices[0].message.content
        title = re.search(r'\*\*Título:\*\*(.*?)\n', response).group(1).strip()
        summary = re.search(r'\*\*Resumen:\*\*(.*?)\n\n', response, re.DOTALL).group(1).strip()
        tags = re.search(r'\*\*Tags:\*\*(.*?)$', response, re.DOTALL).group(1).strip().split()

        return title, summary, tags

    def generate_prompt(self, context: str) -> str:
        """
        Generate a dynamic prompt using OpenAI API based on the provided context.
        If the prompt for the context has already been generated, return it from the cache.

        Args:
            context (str): The context to generate the prompt for.

        Returns:
            str: The generated prompt based on the context.
        """

        if context in self.prompt_cache:
            return self.prompt_cache[context]

        prompt = f"Eres un asistente especializado en artículos sobre {context}. Genera un prompt adecuado para artículos en este contexto. Solo responde con el prompt que debo usar para generar resúmenes, títulos y etiquetas relevantes."

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": f"Genera un prompt adecuado para artículos en el contexto '{context}' sin incluir formato adicional o contenido innecesario."},
                ],
                max_tokens=500,
            )
            response_content = response.choices[0].message.content

            self.prompt_cache[context] = response_content
            return response_content

        except Exception as e:
            print(f"Error al generar el prompt dinámicamente: {e}")
            return "Eres un asistente que proporciona resúmenes, títulos y etiquetas de artículos."